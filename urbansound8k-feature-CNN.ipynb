{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming a panda dataframe from the metadata file\n",
    "data=pd.read_csv(\"../UrbanSound8K/metadata/UrbanSound8K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     990\n",
       "5     936\n",
       "3     925\n",
       "2     888\n",
       "1     873\n",
       "7     838\n",
       "10    837\n",
       "6     823\n",
       "9     816\n",
       "8     806\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of datapoints in each of the folders\n",
    "data[\"fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jackhammer          1000\n",
       "children_playing    1000\n",
       "engine_idling       1000\n",
       "drilling            1000\n",
       "air_conditioner     1000\n",
       "dog_bark            1000\n",
       "street_music        1000\n",
       "siren                929\n",
       "car_horn             429\n",
       "gun_shot             374\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>jackhammer</th>\n",
       "      <th>air_conditioner</th>\n",
       "      <th>children_playing</th>\n",
       "      <th>street_music</th>\n",
       "      <th>dog_bark</th>\n",
       "      <th>drilling</th>\n",
       "      <th>engine_idling</th>\n",
       "      <th>siren</th>\n",
       "      <th>car_horn</th>\n",
       "      <th>gun_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fold1</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>fold2</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>fold3</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>119</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fold4</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>166</td>\n",
       "      <td>59</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fold5</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>71</td>\n",
       "      <td>98</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>fold6</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>fold7</td>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>106</td>\n",
       "      <td>77</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>fold8</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>fold9</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>fold10</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  jackhammer  air_conditioner  children_playing  street_music  \\\n",
       "0   fold1         120              100               100           100   \n",
       "1   fold2         120              100               100           100   \n",
       "2   fold3         120              100               100           100   \n",
       "3   fold4         120              100               100           100   \n",
       "4   fold5         120              100               100           100   \n",
       "5   fold6          68              100               100           100   \n",
       "6   fold7          76              100               100           100   \n",
       "7   fold8          78              100               100           100   \n",
       "8   fold9          82              100               100           100   \n",
       "9  fold10          96              100               100           100   \n",
       "\n",
       "   dog_bark  drilling  engine_idling  siren  car_horn  gun_shot  \n",
       "0       100       100             96     86        36        35  \n",
       "1       100       100            100     91        42        35  \n",
       "2       100       100            107    119        43        36  \n",
       "3       100       100            107    166        59        38  \n",
       "4       100       100            107     71        98        40  \n",
       "5       100       100            107     74        28        46  \n",
       "6       100       100            106     77        28        51  \n",
       "7       100       100             88     80        30        30  \n",
       "8       100       100             89     82        32        31  \n",
       "9       100       100             93     83        33        32  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at the class distribution of each fold to see how balanced the dataset is, it looks like the dataset is not perfectly balanced.\n",
    "appended = []\n",
    "for i in range(1,11):\n",
    "    appended.append(data[data.fold == i]['class'].value_counts())\n",
    "    \n",
    "class_distribution = pd.DataFrame(appended)\n",
    "class_distribution = class_distribution.reset_index()\n",
    "class_distribution['index'] = [\"fold\"+str(x) for x in range(1,11)]\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa import display\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 14), (40, 14), (40, 14), (40, 14), (40, 14))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature set\n",
    "#This file is of a dog bark\n",
    "y,sr=librosa.load(\"../UrbanSound8K/audio/fold5/100032-3-0-0.wav\")\n",
    "mfccs = librosa.feature.mfcc(y, sr, n_mfcc=40)\n",
    "melspectrogram =librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000)\n",
    "chroma_stft=librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40)\n",
    "chroma_cq =librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40)\n",
    "chroma_cens =librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40)\n",
    "melspectrogram.shape,chroma_stft.shape,chroma_cq.shape,chroma_cens.shape,mfccs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450149605da146f0a685d2c3e6e58a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8732), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ync-mb/anaconda3/lib/python3.7/site-packages/librosa/core/pitch.py:146: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#preprocessing using entire feature set\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "XX=[]\n",
    "YY=[]\n",
    "path=\"../UrbanSound8K/audio/fold\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    fold_no=str(data.iloc[i][\"fold\"])\n",
    "    file=data.iloc[i][\"slice_file_name\"]\n",
    "    label=data.iloc[i][\"classID\"]\n",
    "    filename=path+fold_no+\"/\"+file\n",
    "    y,sr=librosa.load(filename)\n",
    "    \n",
    "    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    \n",
    "#     rmse = librosa.feature.rms(y=y); rmse40 = np.tile(rmse,40)[0][:40]\n",
    "#     spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr) ; spec_cent40=np.tile(spec_cent[0],40)[:40]\n",
    "#     spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr) ; spec_bw40=np.tile(spec_bw[0],40)[:40]\n",
    "#     contrast = np.mean(librosa.feature.spectral_contrast(y, sr=sr).T,axis=0); contrast40=np.tile(contrast,40)[:40]\n",
    "#     flatness = librosa.feature.spectral_flatness(y=y); flatness40=np.tile(flatness[0],40)[:40]\n",
    "#     rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr); rolloff40=np.tile(rolloff[0],40)[:40]\n",
    "#     poly = librosa.feature.poly_features(y=y,sr=sr); poly40=np.tile(np.append(poly[0][:20],poly[1][:20]),40)[:40]\n",
    "#     tonnetz = np.mean(librosa.feature.tonnetz(y=y,sr=sr).T,axis=0); tonnetz40 = np.tile(tonnetz,40)[:40]\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y=y); zcr40=np.tile(zcr[0][:40],40)[:40]\n",
    "\n",
    "    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens\n",
    "#                                   ,rmse40,spec_cent40,spec_bw40,contrast40,flatness40,rolloff40,poly40,tonnetz40,zcr40)\n",
    "                                  )\n",
    "                                 ),(40,5))\n",
    "#     if(fold_no=='10'):\n",
    "#         x_test.append(features)\n",
    "#         y_test.append(label)\n",
    "#     else:\n",
    "#         x_train.append(features)\n",
    "#         y_train.append(label)\n",
    "    XX.append(features)\n",
    "    YY.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8732, 40, 5), (8732,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the lists into numpy arrays\n",
    "XX=np.array(XX)\n",
    "\n",
    "YY=np.array(YY)\n",
    "\n",
    "XX.shape,YY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping into 2d to save in csv format\n",
    "XX_2d=np.reshape(XX,(XX.shape[0],XX.shape[1]*XX.shape[2]))\n",
    "XX_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"features_5_data.csv\",XX_2d,delimiter=\",\")\n",
    "np.savetxt(\"labels_5_data.csv\",YY,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX = genfromtxt('features_5_data.csv', delimiter=',')\n",
    "# YYY = genfromtxt('labels_5_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,11):\n",
    "    globals()['XX%s' % x] = XX[data.index[data['fold'] == x].tolist(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((873, 40, 5), (806, 40, 5), (837, 40, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX1.shape,XX8.shape,XX10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,11):\n",
    "    globals()['YY%s' % x] = YY[data.index[data['fold'] == x].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((873,), (806,), (837,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY1.shape,YY8.shape,YY10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "yy1 = to_categorical(YY1, num_classes=10)\n",
    "yy2 = to_categorical(YY2, num_classes=10)\n",
    "yy3 = to_categorical(YY3, num_classes=10)\n",
    "yy4 = to_categorical(YY4, num_classes=10)\n",
    "yy5 = to_categorical(YY5, num_classes=10)\n",
    "yy6 = to_categorical(YY6, num_classes=10)\n",
    "yy7 = to_categorical(YY7, num_classes=10)\n",
    "yy8 = to_categorical(YY8, num_classes=10)\n",
    "yy9 = to_categorical(YY9, num_classes=10)\n",
    "yy10 = to_categorical(YY10, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7859, 40, 5, 1), (873, 40, 5, 1))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping to shape required by CNN\n",
    "x_train_n1=np.reshape(x_train_n1,(x_train_n1.shape[0], 40,5,1))\n",
    "x_test_1=np.reshape(x_test_1,(x_test_1.shape[0], 40,5,1))\n",
    "\n",
    "#shapes\n",
    "x_train_n1.shape,x_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_n1=np.vstack((XX2,XX3,XX4,XX5,XX6,XX7,XX8,XX9,XX10))\n",
    "x_test_1=XX1\n",
    "y_train_n1=np.vstack((yy2,yy3,yy4,yy5,yy6,yy7,yy8,yy9,yy10))\n",
    "y_test_1=yy1\n",
    "\n",
    "x_train_n2=np.vstack((XX1,XX3,XX4,XX5,XX6,XX7,XX8,XX9,XX10))\n",
    "x_test_2=XX2\n",
    "y_train_n2=np.vstack((yy1,yy3,yy4,yy5,yy6,yy7,yy8,yy9,yy10))\n",
    "y_test_2=yy2\n",
    "\n",
    "x_train_n3=np.vstack((XX1,XX2,XX4,XX5,XX6,XX7,XX8,XX9,XX10))\n",
    "x_test_3=XX3\n",
    "y_train_n3=np.vstack((yy1,yy2,yy4,yy5,yy6,yy7,yy8,yy9,yy10))\n",
    "y_test_3=yy3\n",
    "\n",
    "x_train_n4=np.vstack((XX1,XX2,XX3,XX5,XX6,XX7,XX8,XX9,XX10))\n",
    "x_test_4=XX4\n",
    "y_train_n4=np.vstack((yy1,yy2,yy3,yy5,yy6,yy7,yy8,yy9,yy10))\n",
    "y_test_4=yy4\n",
    "\n",
    "x_train_n5=np.vstack((XX1,XX2,XX3,XX4,XX6,XX7,XX8,XX9,XX10))\n",
    "x_test_5=XX5\n",
    "y_train_n5=np.vstack((yy1,yy2,yy3,yy4,yy6,yy7,yy8,yy9,yy10))\n",
    "y_test_5=yy5\n",
    "\n",
    "x_train_n6=np.vstack((XX1,XX2,XX3,XX4,XX5,XX7,XX8,XX9,XX10))\n",
    "x_test_6=XX6\n",
    "y_train_n6=np.vstack((yy1,yy2,yy3,yy4,yy5,yy7,yy8,yy9,yy10))\n",
    "y_test_6=yy6\n",
    "\n",
    "x_train_n7=np.vstack((XX1,XX2,XX3,XX4,XX5,XX6,XX8,XX9,XX10))\n",
    "x_test_7=XX7\n",
    "y_train_n7=np.vstack((yy1,yy2,yy3,yy4,yy5,yy6,yy8,yy9,yy10))\n",
    "y_test_7=yy7\n",
    "\n",
    "x_train_n8=np.vstack((XX1,XX2,XX3,XX4,XX5,XX6,XX7,XX9,XX10))\n",
    "x_test_8=XX8\n",
    "y_train_n8=np.vstack((yy1,yy2,yy3,yy4,yy5,yy6,yy7,yy9,yy10))\n",
    "y_test_8=yy8\n",
    "\n",
    "x_train_n9=np.vstack((XX1,XX2,XX3,XX4,XX5,XX6,XX7,XX8,XX10))\n",
    "x_test_9=XX9\n",
    "y_train_n9=np.vstack((yy1,yy2,yy3,yy4,yy5,yy6,yy7,yy8,yy10))\n",
    "y_test_9=yy9\n",
    "\n",
    "x_train_n10=np.vstack((XX1,XX2,XX3,XX4,XX5,XX6,XX7,XX8,XX9))\n",
    "x_test_10=XX10\n",
    "y_train_n10=np.vstack((yy1,yy2,yy3,yy4,yy5,yy6,yy7,yy8,yy9))\n",
    "y_test_10=yy10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping to shape required by CNN\n",
    "x_train_n1=np.reshape(x_train_n1,(x_train_n1.shape[0], 40,5,1))\n",
    "x_test_1=np.reshape(x_test_1,(x_test_1.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n2=np.reshape(x_train_n2,(x_train_n2.shape[0], 40,5,1))\n",
    "x_test_2=np.reshape(x_test_2,(x_test_2.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n3=np.reshape(x_train_n3,(x_train_n3.shape[0], 40,5,1))\n",
    "x_test_3=np.reshape(x_test_3,(x_test_3.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n4=np.reshape(x_train_n4,(x_train_n4.shape[0], 40,5,1))\n",
    "x_test_4=np.reshape(x_test_4,(x_test_4.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n5=np.reshape(x_train_n5,(x_train_n5.shape[0], 40,5,1))\n",
    "x_test_5=np.reshape(x_test_5,(x_test_5.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n6=np.reshape(x_train_n6,(x_train_n6.shape[0], 40,5,1))\n",
    "x_test_6=np.reshape(x_test_6,(x_test_6.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n7=np.reshape(x_train_n7,(x_train_n7.shape[0], 40,5,1))\n",
    "x_test_7=np.reshape(x_test_7,(x_test_7.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n8=np.reshape(x_train_n8,(x_train_n8.shape[0], 40,5,1))\n",
    "x_test_8=np.reshape(x_test_8,(x_test_8.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n9=np.reshape(x_train_n9,(x_train_n9.shape[0], 40,5,1))\n",
    "x_test_9=np.reshape(x_test_9,(x_test_9.shape[0], 40,5,1))\n",
    "\n",
    "x_train_n10=np.reshape(x_train_n10,(x_train_n10.shape[0], 40,5,1))\n",
    "x_test_10=np.reshape(x_test_10,(x_test_10.shape[0], 40,5,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrains=[x_train_n1,x_train_n2,x_train_n3,x_train_n4,x_train_n5,\n",
    "         x_train_n6,x_train_n7,x_train_n8,x_train_n9,x_train_n10]\n",
    "\n",
    "xtests=[x_test_1,x_test_2,x_test_3,x_test_4,x_test_5,\n",
    "         x_test_6,x_test_7,x_test_8,x_test_9,x_test_10]\n",
    "\n",
    "ytrains=[y_train_n1,y_train_n2,y_train_n3,y_train_n4,y_train_n5,\n",
    "         y_train_n6,y_train_n7,y_train_n8,y_train_n9,y_train_n10]\n",
    "\n",
    "ytests=[y_test_1,y_test_2,y_test_3,y_test_4,y_test_5,\n",
    "         y_test_6,y_test_7,y_test_8,y_test_9,y_test_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7859 samples, validate on 873 samples\n",
      "Epoch 1/30\n",
      "7859/7859 [==============================] - 418s 53ms/step - loss: 2.0948 - acc: 0.2741 - val_loss: 1.6994 - val_acc: 0.4467\n",
      "Epoch 2/30\n",
      "7859/7859 [==============================] - 41s 5ms/step - loss: 1.5091 - acc: 0.4731 - val_loss: 1.3826 - val_acc: 0.5567\n",
      "Epoch 3/30\n",
      "7859/7859 [==============================] - 88s 11ms/step - loss: 1.2075 - acc: 0.5903 - val_loss: 1.4100 - val_acc: 0.5418\n",
      "Epoch 4/30\n",
      "7859/7859 [==============================] - 59s 8ms/step - loss: 1.0498 - acc: 0.6440 - val_loss: 1.3507 - val_acc: 0.5762\n",
      "Epoch 5/30\n",
      "7859/7859 [==============================] - 66s 8ms/step - loss: 0.9222 - acc: 0.6897 - val_loss: 1.3983 - val_acc: 0.5441\n",
      "Epoch 6/30\n",
      "7859/7859 [==============================] - 49s 6ms/step - loss: 0.8299 - acc: 0.7238 - val_loss: 1.3248 - val_acc: 0.5739\n",
      "Epoch 7/30\n",
      "7859/7859 [==============================] - 60s 8ms/step - loss: 0.7862 - acc: 0.7445 - val_loss: 1.5594 - val_acc: 0.5590\n",
      "Epoch 8/30\n",
      "7859/7859 [==============================] - 44s 6ms/step - loss: 0.7574 - acc: 0.7545 - val_loss: 1.3951 - val_acc: 0.5521\n",
      "Epoch 9/30\n",
      "7859/7859 [==============================] - 54s 7ms/step - loss: 0.6576 - acc: 0.7833 - val_loss: 1.5236 - val_acc: 0.5911\n",
      "Epoch 10/30\n",
      "7859/7859 [==============================] - 36s 5ms/step - loss: 0.6384 - acc: 0.7944 - val_loss: 1.6020 - val_acc: 0.5624\n",
      "Epoch 11/30\n",
      "7859/7859 [==============================] - 43s 6ms/step - loss: 0.6074 - acc: 0.8040 - val_loss: 1.4522 - val_acc: 0.5842\n",
      "Epoch 12/30\n",
      "7859/7859 [==============================] - 35s 4ms/step - loss: 0.5667 - acc: 0.8133 - val_loss: 1.6296 - val_acc: 0.5430\n",
      "Epoch 13/30\n",
      "7859/7859 [==============================] - 44s 6ms/step - loss: 0.5448 - acc: 0.8267 - val_loss: 1.6197 - val_acc: 0.5647\n",
      "Epoch 14/30\n",
      "7859/7859 [==============================] - 37s 5ms/step - loss: 0.5316 - acc: 0.8308 - val_loss: 1.6821 - val_acc: 0.5567\n",
      "Epoch 15/30\n",
      "7859/7859 [==============================] - 35s 4ms/step - loss: 0.5185 - acc: 0.8350 - val_loss: 1.6260 - val_acc: 0.5876\n",
      "Epoch 16/30\n",
      "7859/7859 [==============================] - 35s 4ms/step - loss: 0.5017 - acc: 0.8389 - val_loss: 1.6877 - val_acc: 0.5636\n",
      "Epoch 17/30\n",
      "7859/7859 [==============================] - 34s 4ms/step - loss: 0.4866 - acc: 0.8432 - val_loss: 1.5464 - val_acc: 0.5704\n",
      "Epoch 18/30\n",
      "7859/7859 [==============================] - 34s 4ms/step - loss: 0.4452 - acc: 0.8567 - val_loss: 1.6364 - val_acc: 0.5853\n",
      "Epoch 19/30\n",
      "7859/7859 [==============================] - 33s 4ms/step - loss: 0.4225 - acc: 0.8658 - val_loss: 1.9094 - val_acc: 0.5750\n",
      "Epoch 20/30\n",
      "7859/7859 [==============================] - 30s 4ms/step - loss: 0.3924 - acc: 0.8735 - val_loss: 2.0574 - val_acc: 0.5624\n",
      "Epoch 21/30\n",
      "7859/7859 [==============================] - 33s 4ms/step - loss: 0.3984 - acc: 0.8717 - val_loss: 1.7725 - val_acc: 0.5670\n",
      "Epoch 22/30\n",
      "7859/7859 [==============================] - 30s 4ms/step - loss: 0.4068 - acc: 0.8700 - val_loss: 1.9040 - val_acc: 0.5785\n",
      "Epoch 23/30\n",
      "7859/7859 [==============================] - 29s 4ms/step - loss: 0.3705 - acc: 0.8794 - val_loss: 1.8180 - val_acc: 0.5556\n",
      "Epoch 24/30\n",
      "7859/7859 [==============================] - 30s 4ms/step - loss: 0.3485 - acc: 0.8834 - val_loss: 2.1240 - val_acc: 0.5716\n",
      "Epoch 25/30\n",
      "7859/7859 [==============================] - 29s 4ms/step - loss: 0.3666 - acc: 0.8842 - val_loss: 2.0409 - val_acc: 0.5670\n",
      "Epoch 26/30\n",
      "7859/7859 [==============================] - 29s 4ms/step - loss: 0.3687 - acc: 0.8832 - val_loss: 1.8380 - val_acc: 0.5922\n",
      "Epoch 27/30\n",
      "7859/7859 [==============================] - 29s 4ms/step - loss: 0.3505 - acc: 0.8890 - val_loss: 1.8843 - val_acc: 0.5739\n",
      "Epoch 28/30\n",
      "7859/7859 [==============================] - 30s 4ms/step - loss: 0.3575 - acc: 0.8857 - val_loss: 1.9364 - val_acc: 0.5762\n",
      "Epoch 29/30\n",
      "7859/7859 [==============================] - 28s 4ms/step - loss: 0.3368 - acc: 0.8945 - val_loss: 1.7843 - val_acc: 0.5808\n",
      "Epoch 30/30\n",
      "7859/7859 [==============================] - 29s 4ms/step - loss: 0.3543 - acc: 0.8918 - val_loss: 1.7518 - val_acc: 0.5670\n",
      "7859/7859 [==============================] - 10s 1ms/step\n",
      "873/873 [==============================] - 1s 1ms/step\n",
      "acc: 56.70%\n",
      "Train on 7844 samples, validate on 888 samples\n",
      "Epoch 1/30\n",
      "7844/7844 [==============================] - 62s 8ms/step - loss: 2.1267 - acc: 0.2580 - val_loss: 1.7555 - val_acc: 0.3784\n",
      "Epoch 2/30\n",
      "7844/7844 [==============================] - 30s 4ms/step - loss: 1.5764 - acc: 0.4398 - val_loss: 1.4650 - val_acc: 0.4764\n",
      "Epoch 3/30\n",
      "7844/7844 [==============================] - 30s 4ms/step - loss: 1.2766 - acc: 0.5720 - val_loss: 1.2918 - val_acc: 0.5214\n",
      "Epoch 4/30\n",
      "7844/7844 [==============================] - 33s 4ms/step - loss: 1.1208 - acc: 0.6221 - val_loss: 1.4677 - val_acc: 0.5721\n",
      "Epoch 5/30\n",
      "7844/7844 [==============================] - 31s 4ms/step - loss: 0.9691 - acc: 0.6775 - val_loss: 1.1781 - val_acc: 0.5923\n",
      "Epoch 6/30\n",
      "7844/7844 [==============================] - 31s 4ms/step - loss: 0.8998 - acc: 0.7027 - val_loss: 1.3287 - val_acc: 0.6002\n",
      "Epoch 7/30\n",
      "7844/7844 [==============================] - 28s 4ms/step - loss: 0.8425 - acc: 0.7195 - val_loss: 1.3205 - val_acc: 0.5507\n",
      "Epoch 8/30\n",
      "7844/7844 [==============================] - 28s 4ms/step - loss: 0.7932 - acc: 0.7457 - val_loss: 1.4140 - val_acc: 0.5507\n",
      "Epoch 9/30\n",
      "7844/7844 [==============================] - 27s 3ms/step - loss: 0.7161 - acc: 0.7629 - val_loss: 1.3543 - val_acc: 0.5552\n",
      "Epoch 10/30\n",
      "7844/7844 [==============================] - 30s 4ms/step - loss: 0.6689 - acc: 0.7798 - val_loss: 1.2732 - val_acc: 0.5800\n",
      "Epoch 11/30\n",
      "7844/7844 [==============================] - 34s 4ms/step - loss: 0.6337 - acc: 0.7960 - val_loss: 1.4976 - val_acc: 0.5957\n",
      "Epoch 12/30\n",
      "7844/7844 [==============================] - 32s 4ms/step - loss: 0.5943 - acc: 0.8083 - val_loss: 1.5939 - val_acc: 0.6227\n",
      "Epoch 13/30\n",
      "7844/7844 [==============================] - 30s 4ms/step - loss: 0.5885 - acc: 0.8055 - val_loss: 1.3983 - val_acc: 0.5766\n",
      "Epoch 14/30\n",
      "7844/7844 [==============================] - 28s 4ms/step - loss: 0.5378 - acc: 0.8230 - val_loss: 1.4027 - val_acc: 0.5867\n",
      "Epoch 15/30\n",
      "7844/7844 [==============================] - 30s 4ms/step - loss: 0.5336 - acc: 0.8280 - val_loss: 1.4474 - val_acc: 0.6092\n",
      "Epoch 16/30\n",
      "7844/7844 [==============================] - 37s 5ms/step - loss: 0.5314 - acc: 0.8330 - val_loss: 1.3413 - val_acc: 0.6002\n",
      "Epoch 17/30\n",
      "7844/7844 [==============================] - 44s 6ms/step - loss: 0.5128 - acc: 0.8325 - val_loss: 1.4033 - val_acc: 0.6205\n",
      "Epoch 18/30\n",
      "7844/7844 [==============================] - 34s 4ms/step - loss: 0.4740 - acc: 0.8457 - val_loss: 1.6142 - val_acc: 0.5901\n",
      "Epoch 19/30\n",
      "7844/7844 [==============================] - 32s 4ms/step - loss: 0.4363 - acc: 0.8566 - val_loss: 1.6087 - val_acc: 0.5833\n",
      "Epoch 20/30\n",
      "7844/7844 [==============================] - 30s 4ms/step - loss: 0.4332 - acc: 0.8660 - val_loss: 1.4150 - val_acc: 0.6047\n",
      "Epoch 21/30\n",
      "7844/7844 [==============================] - 29s 4ms/step - loss: 0.4491 - acc: 0.8623 - val_loss: 1.5350 - val_acc: 0.6205\n",
      "Epoch 22/30\n",
      "7844/7844 [==============================] - 28s 4ms/step - loss: 0.4169 - acc: 0.8670 - val_loss: 1.7797 - val_acc: 0.6104\n",
      "Epoch 23/30\n",
      "7844/7844 [==============================] - 27s 3ms/step - loss: 0.3898 - acc: 0.8751 - val_loss: 1.5125 - val_acc: 0.6036\n",
      "Epoch 24/30\n",
      "7844/7844 [==============================] - 30s 4ms/step - loss: 0.4062 - acc: 0.8673 - val_loss: 1.6963 - val_acc: 0.5608\n",
      "Epoch 25/30\n",
      "7844/7844 [==============================] - 29s 4ms/step - loss: 0.3883 - acc: 0.8751 - val_loss: 1.3745 - val_acc: 0.6092\n",
      "Epoch 26/30\n",
      "7844/7844 [==============================] - 28s 4ms/step - loss: 0.3682 - acc: 0.8808 - val_loss: 1.5528 - val_acc: 0.6216\n",
      "Epoch 27/30\n",
      "7844/7844 [==============================] - 28s 4ms/step - loss: 0.3644 - acc: 0.8832 - val_loss: 1.5597 - val_acc: 0.5653\n",
      "Epoch 28/30\n",
      "7844/7844 [==============================] - 31s 4ms/step - loss: 0.3621 - acc: 0.8856 - val_loss: 1.7331 - val_acc: 0.5968\n",
      "Epoch 29/30\n",
      "7844/7844 [==============================] - 40s 5ms/step - loss: 0.3594 - acc: 0.8831 - val_loss: 1.4935 - val_acc: 0.6160\n",
      "Epoch 30/30\n",
      "7844/7844 [==============================] - 39s 5ms/step - loss: 0.3735 - acc: 0.8825 - val_loss: 1.8659 - val_acc: 0.6014\n",
      "7844/7844 [==============================] - 13s 2ms/step\n",
      "888/888 [==============================] - 1s 2ms/step\n",
      "acc: 60.14%\n",
      "Train on 7807 samples, validate on 925 samples\n",
      "Epoch 1/30\n",
      "7807/7807 [==============================] - 54s 7ms/step - loss: 2.1032 - acc: 0.2586 - val_loss: 1.7016 - val_acc: 0.4151\n",
      "Epoch 2/30\n",
      "7807/7807 [==============================] - 27s 3ms/step - loss: 1.6641 - acc: 0.4136 - val_loss: 1.4612 - val_acc: 0.4973\n",
      "Epoch 3/30\n",
      "7807/7807 [==============================] - 29s 4ms/step - loss: 1.3057 - acc: 0.5445 - val_loss: 1.3683 - val_acc: 0.5459\n",
      "Epoch 4/30\n",
      "7807/7807 [==============================] - 28s 4ms/step - loss: 1.1199 - acc: 0.6173 - val_loss: 1.3349 - val_acc: 0.5708\n",
      "Epoch 5/30\n",
      "7807/7807 [==============================] - 28s 4ms/step - loss: 1.0138 - acc: 0.6611 - val_loss: 1.4353 - val_acc: 0.5384\n",
      "Epoch 6/30\n",
      "7807/7807 [==============================] - 27s 3ms/step - loss: 0.9311 - acc: 0.6898 - val_loss: 1.3485 - val_acc: 0.5568\n",
      "Epoch 7/30\n",
      "7807/7807 [==============================] - 27s 3ms/step - loss: 0.8510 - acc: 0.7179 - val_loss: 1.4519 - val_acc: 0.5903\n",
      "Epoch 8/30\n",
      "7807/7807 [==============================] - 30s 4ms/step - loss: 0.7804 - acc: 0.7386 - val_loss: 1.4470 - val_acc: 0.5362\n",
      "Epoch 9/30\n",
      "7807/7807 [==============================] - 28s 4ms/step - loss: 0.7524 - acc: 0.7504 - val_loss: 1.4640 - val_acc: 0.5232\n",
      "Epoch 10/30\n",
      "7807/7807 [==============================] - 28s 4ms/step - loss: 0.7018 - acc: 0.7732 - val_loss: 1.5971 - val_acc: 0.5297\n",
      "Epoch 11/30\n",
      "7807/7807 [==============================] - 37s 5ms/step - loss: 0.6478 - acc: 0.7920 - val_loss: 1.4666 - val_acc: 0.5503\n",
      "Epoch 12/30\n",
      "7807/7807 [==============================] - 35s 4ms/step - loss: 0.6233 - acc: 0.7998 - val_loss: 1.5358 - val_acc: 0.5114\n",
      "Epoch 13/30\n",
      "7807/7807 [==============================] - 41s 5ms/step - loss: 0.5975 - acc: 0.8035 - val_loss: 1.4314 - val_acc: 0.5708\n",
      "Epoch 14/30\n",
      "7807/7807 [==============================] - 31s 4ms/step - loss: 0.5516 - acc: 0.8150 - val_loss: 1.5160 - val_acc: 0.5730\n",
      "Epoch 15/30\n",
      "7807/7807 [==============================] - 25s 3ms/step - loss: 0.5409 - acc: 0.8254 - val_loss: 1.4804 - val_acc: 0.5600\n",
      "Epoch 16/30\n",
      "7807/7807 [==============================] - 26s 3ms/step - loss: 0.5118 - acc: 0.8296 - val_loss: 1.7178 - val_acc: 0.5341\n",
      "Epoch 17/30\n",
      "7807/7807 [==============================] - 25s 3ms/step - loss: 0.5516 - acc: 0.8198 - val_loss: 1.6100 - val_acc: 0.5459\n",
      "Epoch 18/30\n",
      "7807/7807 [==============================] - 27s 3ms/step - loss: 0.4937 - acc: 0.8392 - val_loss: 1.5026 - val_acc: 0.5589\n",
      "Epoch 19/30\n",
      "7807/7807 [==============================] - 28s 4ms/step - loss: 0.4612 - acc: 0.8455 - val_loss: 1.7151 - val_acc: 0.5557\n",
      "Epoch 20/30\n",
      "7807/7807 [==============================] - 25s 3ms/step - loss: 0.4511 - acc: 0.8509 - val_loss: 1.6782 - val_acc: 0.5438\n",
      "Epoch 21/30\n",
      "7807/7807 [==============================] - 24s 3ms/step - loss: 0.4153 - acc: 0.8704 - val_loss: 1.5671 - val_acc: 0.5751\n",
      "Epoch 22/30\n",
      "7807/7807 [==============================] - 30s 4ms/step - loss: 0.4259 - acc: 0.8597 - val_loss: 1.5781 - val_acc: 0.5708\n",
      "Epoch 23/30\n",
      "7807/7807 [==============================] - 32s 4ms/step - loss: 0.3991 - acc: 0.8700 - val_loss: 1.6723 - val_acc: 0.5665\n",
      "Epoch 24/30\n",
      "7807/7807 [==============================] - 29s 4ms/step - loss: 0.3899 - acc: 0.8760 - val_loss: 1.7612 - val_acc: 0.5589\n",
      "Epoch 25/30\n",
      "7807/7807 [==============================] - 29s 4ms/step - loss: 0.3814 - acc: 0.8749 - val_loss: 1.8001 - val_acc: 0.5524\n",
      "Epoch 26/30\n",
      "7807/7807 [==============================] - 29s 4ms/step - loss: 0.4210 - acc: 0.8672 - val_loss: 1.7839 - val_acc: 0.5795\n",
      "Epoch 27/30\n",
      "7807/7807 [==============================] - 29s 4ms/step - loss: 0.3938 - acc: 0.8737 - val_loss: 1.7668 - val_acc: 0.5611\n",
      "Epoch 28/30\n",
      "7807/7807 [==============================] - 28s 4ms/step - loss: 0.3974 - acc: 0.8696 - val_loss: 1.5244 - val_acc: 0.5643\n",
      "Epoch 29/30\n",
      "7807/7807 [==============================] - 32s 4ms/step - loss: 0.3848 - acc: 0.8786 - val_loss: 1.7809 - val_acc: 0.5481\n",
      "Epoch 30/30\n",
      "7807/7807 [==============================] - 35s 4ms/step - loss: 0.3714 - acc: 0.8790 - val_loss: 1.6190 - val_acc: 0.5762\n",
      "7807/7807 [==============================] - 13s 2ms/step\n",
      "925/925 [==============================] - 2s 2ms/step\n",
      "acc: 57.62%\n",
      "Train on 7742 samples, validate on 990 samples\n",
      "Epoch 1/30\n",
      "7742/7742 [==============================] - 63s 8ms/step - loss: 2.1140 - acc: 0.2634 - val_loss: 1.7185 - val_acc: 0.4414\n",
      "Epoch 2/30\n",
      "7742/7742 [==============================] - 31s 4ms/step - loss: 1.6012 - acc: 0.4303 - val_loss: 1.4236 - val_acc: 0.5141\n",
      "Epoch 3/30\n",
      "7742/7742 [==============================] - 32s 4ms/step - loss: 1.2863 - acc: 0.5509 - val_loss: 1.2300 - val_acc: 0.5889\n",
      "Epoch 4/30\n",
      "7742/7742 [==============================] - 28s 4ms/step - loss: 1.1440 - acc: 0.6080 - val_loss: 1.1572 - val_acc: 0.5919\n",
      "Epoch 5/30\n",
      "7742/7742 [==============================] - 28s 4ms/step - loss: 1.0033 - acc: 0.6624 - val_loss: 1.1635 - val_acc: 0.5838\n",
      "Epoch 6/30\n",
      "7742/7742 [==============================] - 29s 4ms/step - loss: 0.8920 - acc: 0.6965 - val_loss: 1.3540 - val_acc: 0.5465\n",
      "Epoch 7/30\n",
      "7742/7742 [==============================] - 26s 3ms/step - loss: 0.8361 - acc: 0.7253 - val_loss: 1.4470 - val_acc: 0.4899\n",
      "Epoch 8/30\n",
      "7742/7742 [==============================] - 26s 3ms/step - loss: 0.7863 - acc: 0.7450 - val_loss: 1.3313 - val_acc: 0.5778\n",
      "Epoch 9/30\n",
      "7742/7742 [==============================] - 26s 3ms/step - loss: 0.7341 - acc: 0.7595 - val_loss: 1.3078 - val_acc: 0.5747\n",
      "Epoch 10/30\n",
      "7742/7742 [==============================] - 26s 3ms/step - loss: 0.6828 - acc: 0.7764 - val_loss: 1.3379 - val_acc: 0.5838\n",
      "Epoch 11/30\n",
      "7742/7742 [==============================] - 25s 3ms/step - loss: 0.6947 - acc: 0.7816 - val_loss: 1.2502 - val_acc: 0.5949\n",
      "Epoch 12/30\n",
      "7742/7742 [==============================] - 36s 5ms/step - loss: 0.6156 - acc: 0.8052 - val_loss: 1.4189 - val_acc: 0.5465\n",
      "Epoch 13/30\n",
      "7742/7742 [==============================] - 42s 5ms/step - loss: 0.5879 - acc: 0.8117 - val_loss: 1.2897 - val_acc: 0.5747\n",
      "Epoch 14/30\n",
      "7742/7742 [==============================] - 30s 4ms/step - loss: 0.5912 - acc: 0.8110 - val_loss: 1.3747 - val_acc: 0.6071\n",
      "Epoch 15/30\n",
      "7742/7742 [==============================] - 62s 8ms/step - loss: 0.5389 - acc: 0.8225 - val_loss: 1.4625 - val_acc: 0.5697\n",
      "Epoch 16/30\n",
      "7742/7742 [==============================] - 32s 4ms/step - loss: 0.5319 - acc: 0.8267 - val_loss: 1.4687 - val_acc: 0.5667\n",
      "Epoch 17/30\n",
      "7742/7742 [==============================] - 25s 3ms/step - loss: 0.5211 - acc: 0.8362 - val_loss: 1.5868 - val_acc: 0.5818\n",
      "Epoch 18/30\n",
      "7742/7742 [==============================] - 26s 3ms/step - loss: 0.4852 - acc: 0.8477 - val_loss: 1.4718 - val_acc: 0.5909\n",
      "Epoch 19/30\n",
      "7742/7742 [==============================] - 22s 3ms/step - loss: 0.4681 - acc: 0.8451 - val_loss: 1.4455 - val_acc: 0.6222\n",
      "Epoch 20/30\n",
      "7742/7742 [==============================] - 22s 3ms/step - loss: 0.4408 - acc: 0.8565 - val_loss: 1.4828 - val_acc: 0.5889\n",
      "Epoch 21/30\n",
      "7742/7742 [==============================] - 22s 3ms/step - loss: 0.4396 - acc: 0.8624 - val_loss: 1.3883 - val_acc: 0.5929\n",
      "Epoch 22/30\n",
      "7742/7742 [==============================] - 25s 3ms/step - loss: 0.4275 - acc: 0.8654 - val_loss: 1.4824 - val_acc: 0.6081\n",
      "Epoch 23/30\n",
      "7742/7742 [==============================] - 26s 3ms/step - loss: 0.4118 - acc: 0.8668 - val_loss: 1.5103 - val_acc: 0.6081\n",
      "Epoch 24/30\n",
      "7742/7742 [==============================] - 678s 88ms/step - loss: 0.4005 - acc: 0.8729 - val_loss: 1.5867 - val_acc: 0.6030\n",
      "Epoch 25/30\n",
      "7742/7742 [==============================] - 35s 5ms/step - loss: 0.3906 - acc: 0.8778 - val_loss: 1.4210 - val_acc: 0.5960\n",
      "Epoch 26/30\n",
      "7742/7742 [==============================] - 54s 7ms/step - loss: 0.3965 - acc: 0.8745 - val_loss: 1.5349 - val_acc: 0.6131\n",
      "Epoch 27/30\n",
      "7742/7742 [==============================] - 57s 7ms/step - loss: 0.3589 - acc: 0.8844 - val_loss: 1.6205 - val_acc: 0.6020\n",
      "Epoch 28/30\n",
      "7742/7742 [==============================] - 47s 6ms/step - loss: 0.3673 - acc: 0.8830 - val_loss: 1.4736 - val_acc: 0.6162\n",
      "Epoch 29/30\n",
      "7742/7742 [==============================] - 70s 9ms/step - loss: 0.3503 - acc: 0.8866 - val_loss: 1.6512 - val_acc: 0.5970\n",
      "Epoch 30/30\n",
      "7742/7742 [==============================] - 60s 8ms/step - loss: 0.3654 - acc: 0.8826 - val_loss: 1.5398 - val_acc: 0.5980\n",
      "7742/7742 [==============================] - 48s 6ms/step\n",
      "990/990 [==============================] - 3s 3ms/step\n",
      "acc: 59.80%\n",
      "Train on 7796 samples, validate on 936 samples\n",
      "Epoch 1/30\n",
      "7796/7796 [==============================] - 155s 20ms/step - loss: 2.0813 - acc: 0.2781 - val_loss: 1.7299 - val_acc: 0.3333\n",
      "Epoch 2/30\n",
      "7796/7796 [==============================] - 56s 7ms/step - loss: 1.5555 - acc: 0.4543 - val_loss: 1.4249 - val_acc: 0.5182\n",
      "Epoch 3/30\n",
      "7796/7796 [==============================] - 57s 7ms/step - loss: 1.2555 - acc: 0.5613 - val_loss: 1.3482 - val_acc: 0.5459\n",
      "Epoch 4/30\n",
      "7796/7796 [==============================] - 71s 9ms/step - loss: 1.0996 - acc: 0.6280 - val_loss: 1.2395 - val_acc: 0.5962\n",
      "Epoch 5/30\n",
      "7796/7796 [==============================] - 63s 8ms/step - loss: 0.9751 - acc: 0.6709 - val_loss: 1.2337 - val_acc: 0.6303\n",
      "Epoch 6/30\n",
      "7796/7796 [==============================] - 61s 8ms/step - loss: 0.8785 - acc: 0.7091 - val_loss: 1.1811 - val_acc: 0.5919\n",
      "Epoch 7/30\n",
      "7796/7796 [==============================] - 56s 7ms/step - loss: 0.7802 - acc: 0.7440 - val_loss: 0.9872 - val_acc: 0.6581\n",
      "Epoch 8/30\n",
      "7796/7796 [==============================] - 77s 10ms/step - loss: 0.7298 - acc: 0.7641 - val_loss: 1.1241 - val_acc: 0.6303\n",
      "Epoch 9/30\n",
      "7796/7796 [==============================] - 55s 7ms/step - loss: 0.6816 - acc: 0.7762 - val_loss: 1.1735 - val_acc: 0.6709\n",
      "Epoch 10/30\n",
      "7796/7796 [==============================] - 49s 6ms/step - loss: 0.6756 - acc: 0.7778 - val_loss: 0.9664 - val_acc: 0.6934\n",
      "Epoch 11/30\n",
      "7796/7796 [==============================] - 52s 7ms/step - loss: 0.6294 - acc: 0.7944 - val_loss: 1.1198 - val_acc: 0.6400\n",
      "Epoch 12/30\n",
      "7796/7796 [==============================] - 46s 6ms/step - loss: 0.5845 - acc: 0.8135 - val_loss: 1.1943 - val_acc: 0.6485\n",
      "Epoch 13/30\n",
      "7796/7796 [==============================] - 49s 6ms/step - loss: 0.5625 - acc: 0.8167 - val_loss: 1.0568 - val_acc: 0.6741\n",
      "Epoch 14/30\n",
      "7796/7796 [==============================] - 51s 7ms/step - loss: 0.5208 - acc: 0.8338 - val_loss: 0.9770 - val_acc: 0.6731\n",
      "Epoch 15/30\n",
      "7796/7796 [==============================] - 38s 5ms/step - loss: 0.5052 - acc: 0.8366 - val_loss: 1.0311 - val_acc: 0.7030\n",
      "Epoch 16/30\n",
      "7796/7796 [==============================] - 46s 6ms/step - loss: 0.4874 - acc: 0.8453 - val_loss: 1.1620 - val_acc: 0.6699\n",
      "Epoch 17/30\n",
      "7796/7796 [==============================] - 68s 9ms/step - loss: 0.4513 - acc: 0.8481 - val_loss: 0.9952 - val_acc: 0.6613\n",
      "Epoch 18/30\n",
      "7796/7796 [==============================] - 52s 7ms/step - loss: 0.4406 - acc: 0.8592 - val_loss: 1.0967 - val_acc: 0.6517\n",
      "Epoch 19/30\n",
      "7796/7796 [==============================] - 39s 5ms/step - loss: 0.4149 - acc: 0.8683 - val_loss: 1.0179 - val_acc: 0.6806\n",
      "Epoch 20/30\n",
      "7796/7796 [==============================] - 39s 5ms/step - loss: 0.4132 - acc: 0.8666 - val_loss: 1.0696 - val_acc: 0.7051\n",
      "Epoch 21/30\n",
      "7796/7796 [==============================] - 51s 7ms/step - loss: 0.4506 - acc: 0.8612 - val_loss: 0.9875 - val_acc: 0.6806\n",
      "Epoch 22/30\n",
      "7796/7796 [==============================] - 46s 6ms/step - loss: 0.3850 - acc: 0.8758 - val_loss: 0.9664 - val_acc: 0.7073\n",
      "Epoch 23/30\n",
      "7796/7796 [==============================] - 57s 7ms/step - loss: 0.3735 - acc: 0.8757 - val_loss: 0.9882 - val_acc: 0.6838\n",
      "Epoch 24/30\n",
      "7796/7796 [==============================] - 41s 5ms/step - loss: 0.3733 - acc: 0.8799 - val_loss: 1.1046 - val_acc: 0.6656\n",
      "Epoch 25/30\n",
      "7796/7796 [==============================] - 56s 7ms/step - loss: 0.3681 - acc: 0.8794 - val_loss: 1.0459 - val_acc: 0.6912\n",
      "Epoch 26/30\n",
      "7796/7796 [==============================] - 57s 7ms/step - loss: 0.3511 - acc: 0.8869 - val_loss: 1.1533 - val_acc: 0.6816\n",
      "Epoch 27/30\n",
      "7796/7796 [==============================] - 47s 6ms/step - loss: 0.3473 - acc: 0.8883 - val_loss: 1.1156 - val_acc: 0.7051\n",
      "Epoch 28/30\n",
      "7796/7796 [==============================] - 87s 11ms/step - loss: 0.3410 - acc: 0.8932 - val_loss: 1.1119 - val_acc: 0.6987\n",
      "Epoch 29/30\n",
      "7796/7796 [==============================] - 60s 8ms/step - loss: 0.3753 - acc: 0.8808 - val_loss: 0.9771 - val_acc: 0.6902\n",
      "Epoch 30/30\n",
      "7796/7796 [==============================] - 48s 6ms/step - loss: 0.3196 - acc: 0.8952 - val_loss: 1.1469 - val_acc: 0.6635\n",
      "7796/7796 [==============================] - 20s 3ms/step\n",
      "936/936 [==============================] - 2s 2ms/step\n",
      "acc: 66.35%\n",
      "Train on 7909 samples, validate on 823 samples\n",
      "Epoch 1/30\n",
      "7909/7909 [==============================] - 97s 12ms/step - loss: 2.0632 - acc: 0.2842 - val_loss: 1.8503 - val_acc: 0.3050\n",
      "Epoch 2/30\n",
      "7909/7909 [==============================] - 83s 11ms/step - loss: 1.5082 - acc: 0.4744 - val_loss: 1.6021 - val_acc: 0.4374\n",
      "Epoch 3/30\n",
      "7909/7909 [==============================] - 37s 5ms/step - loss: 1.1943 - acc: 0.5898 - val_loss: 1.5603 - val_acc: 0.4605\n",
      "Epoch 4/30\n",
      "7909/7909 [==============================] - 37s 5ms/step - loss: 1.0253 - acc: 0.6495 - val_loss: 1.6457 - val_acc: 0.4872\n",
      "Epoch 5/30\n",
      "7909/7909 [==============================] - 37s 5ms/step - loss: 0.9425 - acc: 0.6909 - val_loss: 1.4945 - val_acc: 0.5395\n",
      "Epoch 6/30\n",
      "7909/7909 [==============================] - 37s 5ms/step - loss: 0.8469 - acc: 0.7246 - val_loss: 1.4212 - val_acc: 0.5711\n",
      "Epoch 7/30\n",
      "7909/7909 [==============================] - 40s 5ms/step - loss: 0.8117 - acc: 0.7405 - val_loss: 1.3391 - val_acc: 0.5626\n",
      "Epoch 8/30\n",
      "7909/7909 [==============================] - 39s 5ms/step - loss: 0.7148 - acc: 0.7715 - val_loss: 1.3987 - val_acc: 0.5857\n",
      "Epoch 9/30\n",
      "7909/7909 [==============================] - 34s 4ms/step - loss: 0.6736 - acc: 0.7799 - val_loss: 1.5399 - val_acc: 0.5650\n",
      "Epoch 10/30\n",
      "7909/7909 [==============================] - 35s 4ms/step - loss: 0.6384 - acc: 0.7920 - val_loss: 1.4370 - val_acc: 0.5601\n",
      "Epoch 11/30\n",
      "7909/7909 [==============================] - 34s 4ms/step - loss: 0.5942 - acc: 0.8033 - val_loss: 1.5435 - val_acc: 0.5978\n",
      "Epoch 12/30\n",
      "7909/7909 [==============================] - 32s 4ms/step - loss: 0.5810 - acc: 0.8112 - val_loss: 1.3095 - val_acc: 0.6075\n",
      "Epoch 13/30\n",
      "7909/7909 [==============================] - 33s 4ms/step - loss: 0.5116 - acc: 0.8341 - val_loss: 1.3560 - val_acc: 0.5954\n",
      "Epoch 14/30\n",
      "7909/7909 [==============================] - 34s 4ms/step - loss: 0.5380 - acc: 0.8280 - val_loss: 1.4142 - val_acc: 0.6160\n",
      "Epoch 15/30\n",
      "7909/7909 [==============================] - 33s 4ms/step - loss: 0.4890 - acc: 0.8393 - val_loss: 1.5335 - val_acc: 0.5966\n",
      "Epoch 16/30\n",
      "7909/7909 [==============================] - 34s 4ms/step - loss: 0.4462 - acc: 0.8578 - val_loss: 1.6124 - val_acc: 0.6148\n",
      "Epoch 17/30\n",
      "7909/7909 [==============================] - 34s 4ms/step - loss: 0.4600 - acc: 0.8508 - val_loss: 1.4059 - val_acc: 0.6294\n",
      "Epoch 18/30\n",
      "7909/7909 [==============================] - 32s 4ms/step - loss: 0.4226 - acc: 0.8643 - val_loss: 1.3758 - val_acc: 0.5978\n",
      "Epoch 19/30\n",
      "7909/7909 [==============================] - 33s 4ms/step - loss: 0.4095 - acc: 0.8643 - val_loss: 1.3609 - val_acc: 0.6355\n",
      "Epoch 20/30\n",
      "7909/7909 [==============================] - 34s 4ms/step - loss: 0.4302 - acc: 0.8616 - val_loss: 1.4837 - val_acc: 0.5966\n",
      "Epoch 21/30\n",
      "7909/7909 [==============================] - 38s 5ms/step - loss: 0.3737 - acc: 0.8772 - val_loss: 1.3907 - val_acc: 0.5832\n",
      "Epoch 22/30\n",
      "7909/7909 [==============================] - 37s 5ms/step - loss: 0.3940 - acc: 0.8718 - val_loss: 1.3316 - val_acc: 0.6197\n",
      "Epoch 23/30\n",
      "7909/7909 [==============================] - 37s 5ms/step - loss: 0.3907 - acc: 0.8782 - val_loss: 1.4590 - val_acc: 0.6306\n",
      "Epoch 24/30\n",
      "7909/7909 [==============================] - 36s 5ms/step - loss: 0.3685 - acc: 0.8836 - val_loss: 1.5291 - val_acc: 0.5796\n",
      "Epoch 25/30\n",
      "7909/7909 [==============================] - 32s 4ms/step - loss: 0.3470 - acc: 0.8861 - val_loss: 1.3637 - val_acc: 0.5881\n",
      "Epoch 26/30\n",
      "7909/7909 [==============================] - 34s 4ms/step - loss: 0.3697 - acc: 0.8805 - val_loss: 1.4294 - val_acc: 0.5905\n",
      "Epoch 27/30\n",
      "7909/7909 [==============================] - 22s 3ms/step - loss: 0.3457 - acc: 0.8866 - val_loss: 1.5783 - val_acc: 0.5966\n",
      "Epoch 28/30\n",
      "7909/7909 [==============================] - 21s 3ms/step - loss: 0.3199 - acc: 0.8939 - val_loss: 1.3278 - val_acc: 0.6403\n",
      "Epoch 29/30\n",
      "7909/7909 [==============================] - 27s 3ms/step - loss: 0.3193 - acc: 0.8956 - val_loss: 1.4495 - val_acc: 0.6100\n",
      "Epoch 30/30\n",
      "7909/7909 [==============================] - 23s 3ms/step - loss: 0.3159 - acc: 0.9001 - val_loss: 1.4213 - val_acc: 0.6087\n",
      "7909/7909 [==============================] - 8s 1ms/step\n",
      "823/823 [==============================] - 1s 1ms/step\n",
      "acc: 60.87%\n",
      "Train on 7894 samples, validate on 838 samples\n",
      "Epoch 1/30\n",
      "7894/7894 [==============================] - 55s 7ms/step - loss: 2.1378 - acc: 0.2570 - val_loss: 1.7170 - val_acc: 0.3890\n",
      "Epoch 2/30\n",
      "7894/7894 [==============================] - 26s 3ms/step - loss: 1.5794 - acc: 0.4519 - val_loss: 1.3763 - val_acc: 0.5358\n",
      "Epoch 3/30\n",
      "7894/7894 [==============================] - 31s 4ms/step - loss: 1.2610 - acc: 0.5689 - val_loss: 1.0647 - val_acc: 0.5621\n",
      "Epoch 4/30\n",
      "7894/7894 [==============================] - 26s 3ms/step - loss: 1.1091 - acc: 0.6184 - val_loss: 1.1439 - val_acc: 0.5919\n",
      "Epoch 5/30\n",
      "7894/7894 [==============================] - 73s 9ms/step - loss: 0.9949 - acc: 0.6599 - val_loss: 1.0623 - val_acc: 0.6348\n",
      "Epoch 6/30\n",
      "7894/7894 [==============================] - 27s 3ms/step - loss: 0.9092 - acc: 0.6936 - val_loss: 1.0863 - val_acc: 0.6265\n",
      "Epoch 7/30\n",
      "7894/7894 [==============================] - 25s 3ms/step - loss: 0.8267 - acc: 0.7292 - val_loss: 1.0343 - val_acc: 0.6408\n",
      "Epoch 8/30\n",
      "7894/7894 [==============================] - 22s 3ms/step - loss: 0.7629 - acc: 0.7499 - val_loss: 1.2225 - val_acc: 0.5716\n",
      "Epoch 9/30\n",
      "7894/7894 [==============================] - 22s 3ms/step - loss: 0.7116 - acc: 0.7675 - val_loss: 1.1262 - val_acc: 0.6229\n",
      "Epoch 10/30\n",
      "7894/7894 [==============================] - 22s 3ms/step - loss: 0.6650 - acc: 0.7795 - val_loss: 1.0831 - val_acc: 0.6539\n",
      "Epoch 11/30\n",
      "7894/7894 [==============================] - 22s 3ms/step - loss: 0.6203 - acc: 0.8011 - val_loss: 1.0354 - val_acc: 0.6516\n",
      "Epoch 12/30\n",
      "7894/7894 [==============================] - 25s 3ms/step - loss: 0.5823 - acc: 0.8086 - val_loss: 1.1117 - val_acc: 0.6396\n",
      "Epoch 13/30\n",
      "7894/7894 [==============================] - 36s 5ms/step - loss: 0.5815 - acc: 0.8153 - val_loss: 1.0791 - val_acc: 0.6599\n",
      "Epoch 14/30\n",
      "7894/7894 [==============================] - 29s 4ms/step - loss: 0.5515 - acc: 0.8185 - val_loss: 1.1158 - val_acc: 0.6396\n",
      "Epoch 15/30\n",
      "7894/7894 [==============================] - 30s 4ms/step - loss: 0.5042 - acc: 0.8319 - val_loss: 1.1304 - val_acc: 0.6122\n",
      "Epoch 16/30\n",
      "7894/7894 [==============================] - 28s 4ms/step - loss: 0.4793 - acc: 0.8489 - val_loss: 1.1201 - val_acc: 0.6301\n",
      "Epoch 17/30\n",
      "7894/7894 [==============================] - 37s 5ms/step - loss: 0.4842 - acc: 0.8452 - val_loss: 1.2012 - val_acc: 0.6587\n",
      "Epoch 18/30\n",
      "7894/7894 [==============================] - 30s 4ms/step - loss: 0.4686 - acc: 0.8582 - val_loss: 1.1907 - val_acc: 0.5967\n",
      "Epoch 19/30\n",
      "7894/7894 [==============================] - 26s 3ms/step - loss: 0.4756 - acc: 0.8519 - val_loss: 1.1922 - val_acc: 0.6086\n",
      "Epoch 20/30\n",
      "7894/7894 [==============================] - 28s 4ms/step - loss: 0.4450 - acc: 0.8593 - val_loss: 1.1954 - val_acc: 0.6098\n",
      "Epoch 21/30\n",
      "7894/7894 [==============================] - 23s 3ms/step - loss: 0.3989 - acc: 0.8700 - val_loss: 1.2972 - val_acc: 0.6026\n",
      "Epoch 22/30\n",
      "7894/7894 [==============================] - 24s 3ms/step - loss: 0.4172 - acc: 0.8689 - val_loss: 1.0859 - val_acc: 0.6635\n",
      "Epoch 23/30\n",
      "7894/7894 [==============================] - 27s 3ms/step - loss: 0.3964 - acc: 0.8732 - val_loss: 1.1828 - val_acc: 0.6313\n",
      "Epoch 24/30\n",
      "7894/7894 [==============================] - 26s 3ms/step - loss: 0.4364 - acc: 0.8617 - val_loss: 1.1858 - val_acc: 0.6217\n",
      "Epoch 25/30\n",
      "7894/7894 [==============================] - 28s 4ms/step - loss: 0.3678 - acc: 0.8859 - val_loss: 1.1033 - val_acc: 0.6384\n",
      "Epoch 26/30\n",
      "7894/7894 [==============================] - 28s 4ms/step - loss: 0.3769 - acc: 0.8783 - val_loss: 1.1364 - val_acc: 0.6587\n",
      "Epoch 27/30\n",
      "7894/7894 [==============================] - 272s 34ms/step - loss: 0.3498 - acc: 0.8883 - val_loss: 1.2053 - val_acc: 0.6146\n",
      "Epoch 28/30\n",
      "7894/7894 [==============================] - 31s 4ms/step - loss: 0.3268 - acc: 0.8933 - val_loss: 1.2109 - val_acc: 0.6348\n",
      "Epoch 29/30\n",
      "7894/7894 [==============================] - 29s 4ms/step - loss: 0.3319 - acc: 0.8900 - val_loss: 1.1549 - val_acc: 0.6480\n",
      "Epoch 30/30\n",
      "7894/7894 [==============================] - 22s 3ms/step - loss: 0.3640 - acc: 0.8845 - val_loss: 1.1392 - val_acc: 0.6575\n",
      "7894/7894 [==============================] - 11s 1ms/step\n",
      "838/838 [==============================] - 1s 1ms/step\n",
      "acc: 65.75%\n",
      "Train on 7926 samples, validate on 806 samples\n",
      "Epoch 1/30\n",
      "7926/7926 [==============================] - 48s 6ms/step - loss: 2.1339 - acc: 0.2425 - val_loss: 1.7229 - val_acc: 0.4256\n",
      "Epoch 2/30\n",
      "7926/7926 [==============================] - 21s 3ms/step - loss: 1.6068 - acc: 0.4297 - val_loss: 1.4086 - val_acc: 0.5447\n",
      "Epoch 3/30\n",
      "7926/7926 [==============================] - 23s 3ms/step - loss: 1.2736 - acc: 0.5561 - val_loss: 1.1932 - val_acc: 0.6538\n",
      "Epoch 4/30\n",
      "7926/7926 [==============================] - 26s 3ms/step - loss: 1.1066 - acc: 0.6243 - val_loss: 1.1412 - val_acc: 0.6638\n",
      "Epoch 5/30\n",
      "7926/7926 [==============================] - 24s 3ms/step - loss: 0.9743 - acc: 0.6711 - val_loss: 1.2031 - val_acc: 0.6452\n",
      "Epoch 6/30\n",
      "7926/7926 [==============================] - 22s 3ms/step - loss: 0.8765 - acc: 0.7070 - val_loss: 1.1533 - val_acc: 0.6663\n",
      "Epoch 7/30\n",
      "7926/7926 [==============================] - 22s 3ms/step - loss: 0.7982 - acc: 0.7392 - val_loss: 1.1780 - val_acc: 0.6538\n",
      "Epoch 8/30\n",
      "7926/7926 [==============================] - 22s 3ms/step - loss: 0.7339 - acc: 0.7555 - val_loss: 1.1080 - val_acc: 0.6650\n",
      "Epoch 9/30\n",
      "7926/7926 [==============================] - 21s 3ms/step - loss: 0.7279 - acc: 0.7668 - val_loss: 1.1106 - val_acc: 0.6725\n",
      "Epoch 10/30\n",
      "7926/7926 [==============================] - 23s 3ms/step - loss: 0.6701 - acc: 0.7877 - val_loss: 1.1289 - val_acc: 0.6712\n",
      "Epoch 11/30\n",
      "7926/7926 [==============================] - 24s 3ms/step - loss: 0.6186 - acc: 0.7995 - val_loss: 1.1894 - val_acc: 0.6427\n",
      "Epoch 12/30\n",
      "7926/7926 [==============================] - 23s 3ms/step - loss: 0.6060 - acc: 0.8068 - val_loss: 1.2386 - val_acc: 0.6737\n",
      "Epoch 13/30\n",
      "7926/7926 [==============================] - 23s 3ms/step - loss: 0.6003 - acc: 0.8071 - val_loss: 1.1664 - val_acc: 0.6452\n",
      "Epoch 14/30\n",
      "7926/7926 [==============================] - 24s 3ms/step - loss: 0.5378 - acc: 0.8266 - val_loss: 1.3277 - val_acc: 0.6439\n",
      "Epoch 15/30\n",
      "7926/7926 [==============================] - 35s 4ms/step - loss: 0.5024 - acc: 0.8370 - val_loss: 1.1940 - val_acc: 0.6538\n",
      "Epoch 16/30\n",
      "7926/7926 [==============================] - 28s 4ms/step - loss: 0.5322 - acc: 0.8314 - val_loss: 1.2083 - val_acc: 0.6476\n",
      "Epoch 17/30\n",
      "7926/7926 [==============================] - 25s 3ms/step - loss: 0.4763 - acc: 0.8434 - val_loss: 1.3088 - val_acc: 0.6538\n",
      "Epoch 18/30\n",
      "7926/7926 [==============================] - 27s 3ms/step - loss: 0.4397 - acc: 0.8565 - val_loss: 1.2858 - val_acc: 0.6266\n",
      "Epoch 19/30\n",
      "7926/7926 [==============================] - 23s 3ms/step - loss: 0.4223 - acc: 0.8602 - val_loss: 1.0905 - val_acc: 0.6725\n",
      "Epoch 20/30\n",
      "7926/7926 [==============================] - 27s 3ms/step - loss: 0.4412 - acc: 0.8576 - val_loss: 1.2903 - val_acc: 0.6600\n",
      "Epoch 21/30\n",
      "7926/7926 [==============================] - 25s 3ms/step - loss: 0.4371 - acc: 0.8634 - val_loss: 1.1701 - val_acc: 0.6712\n",
      "Epoch 22/30\n",
      "7926/7926 [==============================] - 32s 4ms/step - loss: 0.4164 - acc: 0.8658 - val_loss: 1.2643 - val_acc: 0.6538\n",
      "Epoch 23/30\n",
      "7926/7926 [==============================] - 47s 6ms/step - loss: 0.4228 - acc: 0.8671 - val_loss: 1.2669 - val_acc: 0.6576\n",
      "Epoch 24/30\n",
      "7926/7926 [==============================] - 46s 6ms/step - loss: 0.4195 - acc: 0.8655 - val_loss: 1.2729 - val_acc: 0.6476\n",
      "Epoch 25/30\n",
      "7926/7926 [==============================] - 52s 7ms/step - loss: 0.3869 - acc: 0.8755 - val_loss: 1.4735 - val_acc: 0.6104\n",
      "Epoch 26/30\n",
      "7926/7926 [==============================] - 47s 6ms/step - loss: 0.3836 - acc: 0.8777 - val_loss: 1.2482 - val_acc: 0.6712\n",
      "Epoch 27/30\n",
      "7926/7926 [==============================] - 45s 6ms/step - loss: 0.3531 - acc: 0.8789 - val_loss: 1.5587 - val_acc: 0.6352\n",
      "Epoch 28/30\n",
      "7926/7926 [==============================] - 35s 4ms/step - loss: 0.3478 - acc: 0.8890 - val_loss: 1.4874 - val_acc: 0.6402\n",
      "Epoch 29/30\n",
      "7926/7926 [==============================] - 30s 4ms/step - loss: 0.3571 - acc: 0.8880 - val_loss: 1.3405 - val_acc: 0.6315\n",
      "Epoch 30/30\n",
      "7926/7926 [==============================] - 32s 4ms/step - loss: 0.3425 - acc: 0.8925 - val_loss: 1.3647 - val_acc: 0.6588\n",
      "7926/7926 [==============================] - 10s 1ms/step\n",
      "806/806 [==============================] - 1s 2ms/step\n",
      "acc: 65.88%\n",
      "Train on 7916 samples, validate on 816 samples\n",
      "Epoch 1/30\n",
      "7916/7916 [==============================] - 76s 10ms/step - loss: 2.1303 - acc: 0.2567 - val_loss: 1.6270 - val_acc: 0.3566\n",
      "Epoch 2/30\n",
      "7916/7916 [==============================] - 40s 5ms/step - loss: 1.5775 - acc: 0.4468 - val_loss: 1.3312 - val_acc: 0.5159\n",
      "Epoch 3/30\n",
      "7916/7916 [==============================] - 43s 5ms/step - loss: 1.2688 - acc: 0.5668 - val_loss: 1.2237 - val_acc: 0.5588\n",
      "Epoch 4/30\n",
      "7916/7916 [==============================] - 36s 5ms/step - loss: 1.1000 - acc: 0.6256 - val_loss: 1.2388 - val_acc: 0.5846\n",
      "Epoch 5/30\n",
      "7916/7916 [==============================] - 39s 5ms/step - loss: 0.9860 - acc: 0.6626 - val_loss: 1.0980 - val_acc: 0.6752\n",
      "Epoch 6/30\n",
      "7916/7916 [==============================] - 44s 6ms/step - loss: 0.9061 - acc: 0.6948 - val_loss: 1.1781 - val_acc: 0.6311\n",
      "Epoch 7/30\n",
      "7916/7916 [==============================] - 39s 5ms/step - loss: 0.8271 - acc: 0.7309 - val_loss: 1.1958 - val_acc: 0.6556\n",
      "Epoch 8/30\n",
      "7916/7916 [==============================] - 37s 5ms/step - loss: 0.7602 - acc: 0.7552 - val_loss: 1.3247 - val_acc: 0.6569\n",
      "Epoch 9/30\n",
      "7916/7916 [==============================] - 42s 5ms/step - loss: 0.7399 - acc: 0.7636 - val_loss: 1.0628 - val_acc: 0.7047\n",
      "Epoch 10/30\n",
      "7916/7916 [==============================] - 40s 5ms/step - loss: 0.6832 - acc: 0.7751 - val_loss: 1.1814 - val_acc: 0.6630\n",
      "Epoch 11/30\n",
      "7916/7916 [==============================] - 38s 5ms/step - loss: 0.6664 - acc: 0.7856 - val_loss: 1.3189 - val_acc: 0.6152\n",
      "Epoch 12/30\n",
      "7916/7916 [==============================] - 38s 5ms/step - loss: 0.6164 - acc: 0.7970 - val_loss: 1.2965 - val_acc: 0.6630\n",
      "Epoch 13/30\n",
      "7916/7916 [==============================] - 37s 5ms/step - loss: 0.5621 - acc: 0.8119 - val_loss: 1.4039 - val_acc: 0.6458\n",
      "Epoch 14/30\n",
      "7916/7916 [==============================] - 36s 5ms/step - loss: 0.5385 - acc: 0.8212 - val_loss: 1.2940 - val_acc: 0.6936\n",
      "Epoch 15/30\n",
      "7916/7916 [==============================] - 36s 5ms/step - loss: 0.5089 - acc: 0.8287 - val_loss: 1.2029 - val_acc: 0.6765\n",
      "Epoch 16/30\n",
      "7916/7916 [==============================] - 31s 4ms/step - loss: 0.5125 - acc: 0.8327 - val_loss: 1.3660 - val_acc: 0.7010\n",
      "Epoch 17/30\n",
      "7916/7916 [==============================] - 33s 4ms/step - loss: 0.5065 - acc: 0.8403 - val_loss: 1.2393 - val_acc: 0.6801\n",
      "Epoch 18/30\n",
      "7916/7916 [==============================] - 32s 4ms/step - loss: 0.4806 - acc: 0.8436 - val_loss: 1.3172 - val_acc: 0.6654\n",
      "Epoch 19/30\n",
      "7916/7916 [==============================] - 33s 4ms/step - loss: 0.4575 - acc: 0.8517 - val_loss: 1.4618 - val_acc: 0.6483\n",
      "Epoch 20/30\n",
      "7916/7916 [==============================] - 31s 4ms/step - loss: 0.4237 - acc: 0.8637 - val_loss: 1.3868 - val_acc: 0.6716\n",
      "Epoch 21/30\n",
      "7916/7916 [==============================] - 44s 6ms/step - loss: 0.4380 - acc: 0.8610 - val_loss: 1.3915 - val_acc: 0.6703\n",
      "Epoch 22/30\n",
      "7916/7916 [==============================] - 39s 5ms/step - loss: 0.4096 - acc: 0.8670 - val_loss: 1.2354 - val_acc: 0.6789\n",
      "Epoch 23/30\n",
      "7916/7916 [==============================] - 37s 5ms/step - loss: 0.4281 - acc: 0.8627 - val_loss: 1.5406 - val_acc: 0.6740\n",
      "Epoch 24/30\n",
      "7916/7916 [==============================] - 37s 5ms/step - loss: 0.4429 - acc: 0.8555 - val_loss: 1.3902 - val_acc: 0.6740\n",
      "Epoch 25/30\n",
      "7916/7916 [==============================] - 40s 5ms/step - loss: 0.3704 - acc: 0.8811 - val_loss: 1.3691 - val_acc: 0.6765\n",
      "Epoch 26/30\n",
      "7916/7916 [==============================] - 39s 5ms/step - loss: 0.3683 - acc: 0.8825 - val_loss: 1.3995 - val_acc: 0.6912\n",
      "Epoch 27/30\n",
      "7916/7916 [==============================] - 44s 6ms/step - loss: 0.3613 - acc: 0.8826 - val_loss: 1.3548 - val_acc: 0.6961\n",
      "Epoch 28/30\n",
      "7916/7916 [==============================] - 44s 6ms/step - loss: 0.3908 - acc: 0.8756 - val_loss: 1.2441 - val_acc: 0.6924\n",
      "Epoch 29/30\n",
      "7916/7916 [==============================] - 36s 5ms/step - loss: 0.3905 - acc: 0.8746 - val_loss: 1.3639 - val_acc: 0.6752\n",
      "Epoch 30/30\n",
      "7916/7916 [==============================] - 39s 5ms/step - loss: 0.3505 - acc: 0.8844 - val_loss: 1.2835 - val_acc: 0.7181\n",
      "7916/7916 [==============================] - 13s 2ms/step\n",
      "816/816 [==============================] - 1s 2ms/step\n",
      "acc: 71.81%\n",
      "Train on 7895 samples, validate on 837 samples\n",
      "Epoch 1/30\n",
      "7895/7895 [==============================] - 87s 11ms/step - loss: 2.0935 - acc: 0.2626 - val_loss: 1.6372 - val_acc: 0.3847\n",
      "Epoch 2/30\n",
      "7895/7895 [==============================] - 37s 5ms/step - loss: 1.5598 - acc: 0.4500 - val_loss: 1.2323 - val_acc: 0.5986\n",
      "Epoch 3/30\n",
      "7895/7895 [==============================] - 34s 4ms/step - loss: 1.2483 - acc: 0.5697 - val_loss: 1.1233 - val_acc: 0.6631\n",
      "Epoch 4/30\n",
      "7895/7895 [==============================] - 35s 4ms/step - loss: 1.0847 - acc: 0.6346 - val_loss: 1.1336 - val_acc: 0.6452\n",
      "Epoch 5/30\n",
      "7895/7895 [==============================] - 30s 4ms/step - loss: 0.9762 - acc: 0.6737 - val_loss: 1.0780 - val_acc: 0.6571\n",
      "Epoch 6/30\n",
      "7895/7895 [==============================] - 32s 4ms/step - loss: 0.8849 - acc: 0.7073 - val_loss: 1.0699 - val_acc: 0.6380\n",
      "Epoch 7/30\n",
      "7895/7895 [==============================] - 31s 4ms/step - loss: 0.8437 - acc: 0.7216 - val_loss: 1.2135 - val_acc: 0.6237\n",
      "Epoch 8/30\n",
      "7895/7895 [==============================] - 29s 4ms/step - loss: 0.7812 - acc: 0.7439 - val_loss: 1.0498 - val_acc: 0.6249\n",
      "Epoch 9/30\n",
      "7895/7895 [==============================] - 31s 4ms/step - loss: 0.7128 - acc: 0.7719 - val_loss: 0.9999 - val_acc: 0.6774\n",
      "Epoch 10/30\n",
      "7895/7895 [==============================] - 30s 4ms/step - loss: 0.6555 - acc: 0.7840 - val_loss: 0.8242 - val_acc: 0.7288\n",
      "Epoch 11/30\n",
      "7895/7895 [==============================] - 30s 4ms/step - loss: 0.6158 - acc: 0.7972 - val_loss: 0.9885 - val_acc: 0.6965\n",
      "Epoch 12/30\n",
      "7895/7895 [==============================] - 33s 4ms/step - loss: 0.5747 - acc: 0.8113 - val_loss: 0.9529 - val_acc: 0.6834\n",
      "Epoch 13/30\n",
      "7895/7895 [==============================] - 31s 4ms/step - loss: 0.5678 - acc: 0.8175 - val_loss: 1.0156 - val_acc: 0.6870\n",
      "Epoch 14/30\n",
      "7895/7895 [==============================] - 30s 4ms/step - loss: 0.5446 - acc: 0.8282 - val_loss: 0.9733 - val_acc: 0.6953\n",
      "Epoch 15/30\n",
      "7895/7895 [==============================] - 29s 4ms/step - loss: 0.5339 - acc: 0.8348 - val_loss: 0.8849 - val_acc: 0.7324\n",
      "Epoch 16/30\n",
      "7895/7895 [==============================] - 31s 4ms/step - loss: 0.5276 - acc: 0.8298 - val_loss: 0.9175 - val_acc: 0.7431\n",
      "Epoch 17/30\n",
      "7895/7895 [==============================] - 29s 4ms/step - loss: 0.4652 - acc: 0.8499 - val_loss: 0.9032 - val_acc: 0.7013\n",
      "Epoch 18/30\n",
      "7895/7895 [==============================] - 29s 4ms/step - loss: 0.4548 - acc: 0.8513 - val_loss: 0.9271 - val_acc: 0.7013\n",
      "Epoch 19/30\n",
      "7895/7895 [==============================] - 30s 4ms/step - loss: 0.4349 - acc: 0.8614 - val_loss: 0.9245 - val_acc: 0.7013\n",
      "Epoch 20/30\n",
      "7895/7895 [==============================] - 33s 4ms/step - loss: 0.4112 - acc: 0.8685 - val_loss: 0.9089 - val_acc: 0.7288\n",
      "Epoch 21/30\n",
      "7895/7895 [==============================] - 40s 5ms/step - loss: 0.3883 - acc: 0.8801 - val_loss: 1.0108 - val_acc: 0.6977\n",
      "Epoch 22/30\n",
      "7895/7895 [==============================] - 47s 6ms/step - loss: 0.3719 - acc: 0.8757 - val_loss: 0.8500 - val_acc: 0.7348\n",
      "Epoch 23/30\n",
      "7895/7895 [==============================] - 36s 5ms/step - loss: 0.4108 - acc: 0.8669 - val_loss: 0.8224 - val_acc: 0.7539\n",
      "Epoch 24/30\n",
      "7895/7895 [==============================] - 36s 5ms/step - loss: 0.3847 - acc: 0.8731 - val_loss: 0.9654 - val_acc: 0.7157\n",
      "Epoch 25/30\n",
      "7895/7895 [==============================] - 37s 5ms/step - loss: 0.3781 - acc: 0.8814 - val_loss: 0.9319 - val_acc: 0.7001\n",
      "Epoch 26/30\n",
      "7895/7895 [==============================] - 37s 5ms/step - loss: 0.3850 - acc: 0.8773 - val_loss: 0.9920 - val_acc: 0.7097\n",
      "Epoch 27/30\n",
      "7895/7895 [==============================] - 37s 5ms/step - loss: 0.3576 - acc: 0.8795 - val_loss: 0.8920 - val_acc: 0.7204\n",
      "Epoch 28/30\n",
      "7895/7895 [==============================] - 34s 4ms/step - loss: 0.3303 - acc: 0.8926 - val_loss: 0.8131 - val_acc: 0.7622\n",
      "Epoch 29/30\n",
      "7895/7895 [==============================] - 31s 4ms/step - loss: 0.3165 - acc: 0.8960 - val_loss: 0.8739 - val_acc: 0.7395\n",
      "Epoch 30/30\n",
      "7895/7895 [==============================] - 31s 4ms/step - loss: 0.3081 - acc: 0.9018 - val_loss: 0.8745 - val_acc: 0.7407\n",
      "7895/7895 [==============================] - 11s 1ms/step\n",
      "837/837 [==============================] - 2s 2ms/step\n",
      "acc: 74.07%\n",
      "63.90% (+/- 5.58%)\n"
     ]
    }
   ],
   "source": [
    "cvscores=[]\n",
    "for xn,yn,xt,yt in zip(xtrains,ytrains,xtests,ytests):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,kernel_size=5,strides=1,padding=\"Same\",activation=\"relu\",input_shape=(40,5,1)))\n",
    "    model.add(MaxPooling2D(padding=\"same\"))\n",
    "\n",
    "    model.add(Conv2D(128,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(padding=\"same\"))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256,activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(512,activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "#     model.add(Dense(512,activation=\"relu\"))###\n",
    "#     model.add(Dropout(0.4))###\n",
    "        \n",
    "    model.add(Dense(10,activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    # Fit the model\n",
    "    model.fit(xn,yn,batch_size=50,epochs=30,validation_data=(xt,yt),    verbose=1)    \n",
    "    # evaluate the model\n",
    "    train_loss_score=model.evaluate(xn,yn)\n",
    "    test_loss_score=model.evaluate(xt,yt)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], test_loss_score[1]*100))\n",
    "    cvscores.append(test_loss_score[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.90% (+/- 5.58%)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "# https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56.70103092783505,\n",
       " 60.13513518883301,\n",
       " 57.62162170539031,\n",
       " 59.79797974981443,\n",
       " 66.34615384615384,\n",
       " 60.87484818182768,\n",
       " 65.75178997613365,\n",
       " 65.88089328545792,\n",
       " 71.81372549019608,\n",
       " 74.07407407407408]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
